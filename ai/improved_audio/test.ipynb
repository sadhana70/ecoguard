{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "import IPython\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "new_model = models.load_model('export')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Conf will save the settings we are going to use in this notebook\n",
    "class conf:\n",
    "    sr = 16000\n",
    "    duration = 3\n",
    "    hop_length = 340*duration\n",
    "    fmin = 20\n",
    "    fmax = sr // 2\n",
    "    n_mels = 128\n",
    "    n_fft = n_mels * 20\n",
    "    samples = sr * duration\n",
    "    epochs = 30\n",
    "\n",
    "def read_audio(conf, pathname, trim_long_data):\n",
    "    y, sr = librosa.load(pathname, sr=conf.sr)\n",
    "    # trim silence\n",
    "    if 0 < len(y): # workaround: 0 length causes error\n",
    "        y, _ = librosa.effects.trim(y) # trim, top_db=default(60)\n",
    "    # make it unified length to conf.samples\n",
    "    if len(y) > conf.samples: # long enough\n",
    "        if trim_long_data:\n",
    "            y = y[0:0+conf.samples]\n",
    "    else: # pad blank\n",
    "        padding = conf.samples - len(y)    # add padding at both ends\n",
    "        offset = padding // 2\n",
    "        y = np.pad(y, (offset, conf.samples - len(y) - offset), 'constant')\n",
    "    return y\n",
    "\n",
    "def audio_to_melspectrogram(conf, audio):\n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio, \n",
    "                                                 sr=conf.sr,\n",
    "                                                 n_mels=conf.n_mels,\n",
    "                                                 hop_length=conf.hop_length,\n",
    "                                                 n_fft=conf.n_fft,\n",
    "                                                 fmin=conf.fmin,\n",
    "                                                 fmax=conf.fmax)\n",
    "    spectrogram = librosa.power_to_db(spectrogram)\n",
    "    return spectrogram\n",
    "\n",
    "def show_melspectrogram(conf, mels, title='Log-frequency power spectrogram'):\n",
    "    librosa.display.specshow(mels, x_axis='time', y_axis='mel', \n",
    "                             sr=conf.sr, hop_length=conf.hop_length,\n",
    "                            fmin=conf.fmin, fmax=conf.fmax)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# Load the WAV file\n",
    "file_path = \"download.wav\"\n",
    "def preprocess(file_path):\n",
    "    sig, sr = librosa.load(file_path, sr=16000)\n",
    "\n",
    "    # Define the duration of each clip in seconds\n",
    "    clip_duration = 2  # 2 seconds\n",
    "\n",
    "    num_clips = 3\n",
    "\n",
    "    x_data = []\n",
    "\n",
    "    # Create random clips from the audio file\n",
    "    for i in range(num_clips):\n",
    "        # Generate a random start sample index within the audio signal\n",
    "        start_sample = np.random.randint(0, len(sig) - sr * clip_duration)\n",
    "        \n",
    "        # Extract the clip from the audio signal\n",
    "        clip = sig[start_sample:start_sample + sr * clip_duration]\n",
    "        \n",
    "        # Perform feature extraction (e.g., mel spectrogram)\n",
    "        mel_spec = audio_to_melspectrogram(conf, clip)\n",
    "        \n",
    "        x_data.append(mel_spec)\n",
    "\n",
    "    x_data = np.array(x_data)\n",
    "    return x_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio(audio_data, w, h, threshold_level, tolerence=10):\n",
    "    split_map = []\n",
    "    start = 0\n",
    "    data = np.abs(audio_data)\n",
    "    threshold = threshold_level*np.mean(data[:25000])\n",
    "    inside_sound = False\n",
    "    near = 0\n",
    "    for i in range(0,len(data)-w, h):\n",
    "        win_mean = np.mean(data[i:i+w])\n",
    "        if(win_mean>threshold and not(inside_sound)):\n",
    "            inside_sound = True\n",
    "            start = i\n",
    "        if(win_mean<=threshold and inside_sound and near>tolerence):\n",
    "            inside_sound = False\n",
    "            near = 0\n",
    "            split_map.append([start, i])\n",
    "        if(inside_sound and win_mean<=threshold):\n",
    "            near += 1\n",
    "    return split_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dog', 'chainsaw', 'crackling_fire', 'helicopter', 'rain',\n",
       "       'crying_baby', 'clock_tick', 'sneezing', 'rooster', 'sea_waves'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.array(['dog', 'chainsaw', 'crackling_fire', 'helicopter', 'rain',\n",
    "       'crying_baby', 'clock_tick', 'sneezing', 'rooster', 'sea_waves'], dtype=\"object\")\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "chainsaw\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "chainsaw\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "chainsaw\n"
     ]
    }
   ],
   "source": [
    "# To identify the sounds in the audio, we are going to cut the soundwave into several parts\n",
    "# The clip will be clipped to it's highlight (noisiest) with certain interval\n",
    "\n",
    "sound_clips = preprocess(\"download1.wav\")\n",
    "for clip in sound_clips:\n",
    "    # clip, index = librosa.effects.trim(y[intvl[0]:intvl[1]],       \n",
    "    #                                    top_db=20, frame_length=512, hop_length=64)\n",
    "    # mel_spec = audio_to_melspectrogram(conf, clip)\n",
    "\n",
    "    # testing = np.reshape(testing[:,:32], (128, 32))\n",
    "    testing = np.expand_dims(clip, axis=(0, -1))\n",
    "    # testing = np.reshape(testing[:, :, :32, :], (1, 128, 32, 1))\n",
    "    # testing = np.random.randint(0, 1,size=(1,128,32,1))\n",
    "\n",
    "    pred = new_model.predict(testing)\n",
    "    \n",
    "    # blank = np.zeros(intvl[0]-0)\n",
    "    # blank2 = np.zeros(duration-intvl[1])\n",
    "    # temp = np.append(blank,clip)\n",
    "    # temp = np.append(temp,blank2)\n",
    "    # librosa.display.waveplot(y = temp, sr = sr, )\n",
    "    \n",
    "    # print(\"Clip Number :\", i)\n",
    "    # print(\"Interval from : \", intvl[0]/16000, \" to \",intvl[1]/16000, \"seconds\")\n",
    "    # i += 1\n",
    "    if pred[0][1] > 0.09:\n",
    "        print(\"chainsaw\")\n",
    "    else:\n",
    "        print(\"no chainsaw\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
